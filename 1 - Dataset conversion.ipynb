{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f996514d",
   "metadata": {},
   "source": [
    "Rôle du notebook: conversion des fichiers XMLs en dataset TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e071adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6846e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "citations = []\n",
    "\n",
    "df = pd.read_csv(\"/home/thibault/dev/these/data/raw/datation.tsv\", delimiter=\"\\t\")\n",
    "df = df[df[\"Ignore\"] != \"X\"]\n",
    "for row in df[\"Name of citation level\"]:\n",
    "    if isinstance(row, str):\n",
    "        citations.extend([x.split(\"|\") for x in row.lower().split(\",\")])\n",
    "        \n",
    "names = sorted(list(set(chain.from_iterable((citations)))))\n",
    "\n",
    "final = {\n",
    "    \"chapteer\": \"chapter\",\n",
    "    \"chapitre\": \"chapter\",\n",
    "    \"scholia\": \"comment\",\n",
    "    \"epistula\": \"letter\",\n",
    "    \"carmen\": \"poem\",\n",
    "    \"p\": \"paragraph\",\n",
    "    \"paragra\": \"paragraph\",\n",
    "    \"poeme\": \"poem\"\n",
    "}\n",
    "for name in names:\n",
    "    if name.endswith(\"s\"):\n",
    "        final[name] = name[:-1]\n",
    "final\n",
    "sorted(list(set([final.get(n, n) for n in names])))\n",
    "\n",
    "df[\"Name of citation level\"] = df[\"Name of citation level\"].apply(\n",
    "    lambda x: sorted([final.get(n, n) for part in x.lower().split(\",\") for n in part.split(\"|\")])\\\n",
    "    if isinstance(x, str) else []\n",
    ")\n",
    "df[\"type\"] = df[\"Name of citation level\"].apply(\n",
    "    lambda n: \"versified\" if \"line\" in n or \"poem\" in n else \"prose\"\n",
    ")\n",
    "#df[\"Century\"] = list(range()\n",
    "# -254.0\n",
    "# 1107\n",
    "# df[\"Death\"].max()\n",
    "centuries = list(range(-3, 13))\n",
    "\n",
    "df[\"centuries\"] = None\n",
    "df_cents = []\n",
    "for idx, row in df.iterrows():\n",
    "    birth, death = row[\"Birth\"], row[\"Death\"]\n",
    "    if death % 100 == 0:\n",
    "        death -= 1\n",
    "    df_cents.append([\n",
    "        cent \n",
    "        for cent in centuries \n",
    "        if cent*100 <= birth <= cent*100+99 or \\\n",
    "        cent*100 <= death <= cent*100+99 or \\\n",
    "        birth <= cent*100 <= death\n",
    "    ])\n",
    "df[\"centuries\"] = df_cents\n",
    "\n",
    "df[[\"URN\", \"Name of citation level\", \"type\", \"centuries\"]].to_csv(\"metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f2d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATAS = {\n",
    "    d[\"URN\"]: {k:d[k] for k in d if k != \"URN\"}\n",
    "    for d in df[[\"URN\", \"Name of citation level\", \"type\", \"centuries\"]].to_dict(\"index\").values()\n",
    "}\n",
    "for key, value in list(METADATAS.items()):\n",
    "    if len(key.split(\".\")) == 3:\n",
    "        METADATAS[\".\".join(key.split(\".\")[:2])] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442f303",
   "metadata": {},
   "source": [
    "## Function to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "855cce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "from constants import CATS\n",
    "\n",
    "def msd_to_tsv(attrib, cats=CATS):\n",
    "    local_values = dict([\n",
    "        tuple(elem.split(\"=\"))\n",
    "        for elem in attrib.split(\"|\")\n",
    "        if elem.split(\"=\")[0] in cats\n",
    "    ])\n",
    "    return \"\\t\".join([\n",
    "        local_values.get(cat, \"-\")\n",
    "        for cat in cats\n",
    "    ])\n",
    "\n",
    "import regex as re\n",
    "\n",
    "FORBIDDEN_TOKENS = re.compile(\".*[^\\w\\.,;?!\\\"':\\(\\)]+.*\")\n",
    "NORMALIZE = re.compile(\"['‘’“”«»]+\")\n",
    "\n",
    "def keep(string):\n",
    "    string = NORMALIZE.sub('\"', string)\n",
    "    if FORBIDDEN_TOKENS.match(string):\n",
    "        if string[0] == \"{\" and string[-1] == \"}\":\n",
    "            return True\n",
    "        print(\"Ignored %s\" % string)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def norma(string):\n",
    "    if string[0] == \"{\" and string[-1] == \"}\":\n",
    "        if string[-4:] == \"que}\":\n",
    "            return \"-que\"\n",
    "        if string[-4:] == \"cum}\":\n",
    "            return \"-cum\"\n",
    "        elif string[-3:] == \"ne}\" or  string[-2:] == \"n}\":\n",
    "            return \"-ne\"\n",
    "        elif string[-3:] == \"ue}\" or string[-3:] == \"ve}\":\n",
    "            return \"-ve\"\n",
    "        elif string[-3:] == \"st}\":\n",
    "            return \"est\"\n",
    "        else:\n",
    "            print(string)\n",
    "    return NORMALIZE.sub('\"', string)\n",
    "\n",
    "def make_metadata_token(key, val):\n",
    "    return f\"{key}={val}\"\n",
    "\n",
    "def get_ana(xml):\n",
    "    if xml.xpath(\"//@ana\"):\n",
    "        return list([x for x in xml.xpath(\"//@ana\")[0].split() if x.strip()])\n",
    "    return []\n",
    "\n",
    "def file_to_string(fp: str, label: str, cats=CATS) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open(fp) as f:\n",
    "        xml = ET.parse(f)\n",
    "    urn = xml.xpath(\"//idno[@type='CTS_URN']\")[0].text\n",
    "    key = urn\n",
    "    if urn not in METADATAS:\n",
    "        key = \".\".join(urn.split(\".\")[:2])\n",
    "    if key in METADATAS:\n",
    "        metadata = {\n",
    "            \"urn\": urn,\n",
    "            \"fp\": fp,\n",
    "            \"tags\": get_ana(xml),\n",
    "            \"metadata_token\": [\n",
    "                make_metadata_token(\"WrittenType\", METADATAS[key]['type']),\n",
    "                *[make_metadata_token(\"Century\", c) for c in METADATAS[key][\"centuries\"]],\n",
    "                *[make_metadata_token(\"CitationTypes\", t) for t in METADATAS[key][\"Name of citation level\"]]\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        print(key, fp)\n",
    "    return f\"#[TAG]{label}\\n\" + \\\n",
    "           \"\\n\".join([f'[GENERIC-METADATA]{k}={metadata[k]}' for k in (\"urn\", \"fp\")])+ \"\\n\" + \\\n",
    "           \"\\n\".join([f'[TAGS-METADATA]TAG={tag}' for tag in metadata.get(\"tags\", [])])+ \"\\n\" + \\\n",
    "           \"\\n\".join([\"[TOKEN-METADATA]\"+ m for m in metadata[\"metadata_token\"]]) + \\\n",
    "           f\"\\n[TOKEN-METADATA]{make_metadata_token('Textgroup', urn.split('.')[0])}\\n\" + \\\n",
    "           \"\\n\".join([\n",
    "                f\"{norma(token.text)}\\t\"\n",
    "                f\"{token.attrib['lemma']}\\t\"\n",
    "                f\"{token.attrib['pos']}\\t\"\n",
    "                f\"{msd_to_tsv(token.attrib['msd'], cats=cats)}\"\n",
    "                for token in xml.xpath(\"//w\")\n",
    "                if keep(token.text)\n",
    "            ])\n",
    "\n",
    "def split_dataset(sample, ratio=0.8):\n",
    "    ms = int(ratio*len(sample))\n",
    "    return sample[:ms], sample[ms:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0465128",
   "metadata": {},
   "source": [
    "## Generate full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b8e49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored |\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored /\n",
      "Ignored —\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored -\n",
      "Ignored *\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored †\n",
      "Ignored †\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored =\n",
      "Ignored =\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored *\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored †\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored †\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "{sis}\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored *\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored †\n",
      "{sis}\n",
      "Ignored *\n",
      "Ignored *\n",
      "{sis}\n",
      "{semetipsum}\n",
      "Ignored —\n",
      "Ignored —\n",
      "{sis}\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored =\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored /\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored †\n",
      "Ignored †\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored —\n",
      "{sis}\n",
      "Ignored —\n",
      "{sodes}\n",
      "Ignored †\n",
      "Ignored †\n",
      "Ignored *\n",
      "Ignored |\n",
      "Ignored ]\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored /\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored –\n",
      "Ignored –\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored |\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored ∗\n",
      "Ignored =\n",
      "Ignored –\n",
      "Ignored -\n",
      "Ignored *\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored •\n",
      "Ignored ᾽\n",
      "Ignored ᾽\n",
      "Ignored •\n",
      "Ignored ᾽\n",
      "Ignored ᾽\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored |\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "{XIIII}\n",
      "{XXIIII}\n",
      "{XIIII}\n",
      "Ignored —\n",
      "{semetipsum}\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored |\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored ■\n",
      "Ignored =\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored \\\n",
      "Ignored •\n",
      "{altius1}\n",
      "Ignored -\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored -\n",
      "{XIIII}\n",
      "Ignored —\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored -\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "{s}\n",
      "Ignored \\\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored 〈\n",
      "Ignored 〉\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored –\n",
      "Ignored \\\n",
      "Ignored *\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‹\n",
      "Ignored ›\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored \\\n",
      "{semetipso}\n",
      "Ignored #\n",
      "Ignored #\n",
      "Ignored \\\n",
      "Ignored ]\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored [\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored †\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored \\\n",
      "{sis}\n",
      "Ignored \\\n",
      "Ignored ·\n",
      "Ignored ·\n",
      "Ignored -\n",
      "Ignored ‹\n",
      "Ignored ›\n",
      "Ignored \\\n",
      "Ignored *\n",
      "Ignored -\n",
      "Ignored ‧\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored -\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored -\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored —\n",
      "{semetipso}\n",
      "Ignored +\n",
      "Ignored ■\n",
      "Ignored —\n",
      "Ignored –\n",
      "Ignored –\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored ]\n",
      "Ignored ]\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored \\\n",
      "{XIII.}\n",
      "{s}\n",
      "Ignored §\n",
      "Ignored ­\n",
      "Ignored ‛\n",
      "Ignored ­\n",
      "Ignored ‛\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "{q}\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored ·\n",
      "Ignored ·\n",
      "Ignored ·\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored „\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored \\\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored =\n",
      "Ignored /\n",
      "Ignored /\n",
      "Ignored ∞\n",
      "Ignored ∞\n",
      "Ignored ∞\n",
      "Ignored ∞\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored •\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored ‛\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored —\n",
      "Ignored =\n",
      "Ignored \\\n",
      "{sprevissct}\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored [\n",
      "Ignored \\\n",
      "{s}\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored /\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored —\n",
      "Ignored -\n",
      "Ignored /\n",
      "Ignored -\n",
      "Ignored ⟩\n",
      "Ignored ⟨\n",
      "Ignored ⟩\n",
      "Ignored /\n",
      "Ignored •\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored *\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored ÷\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored *\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored ‛\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored [\n",
      "Ignored ]\n",
      "Ignored \\\n",
      "Ignored —\n",
      "Ignored —\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored †\n",
      "Ignored †\n",
      "Ignored /\n",
      "Ignored ­\n",
      "Ignored ]\n",
      "Ignored ]\n",
      "Ignored *\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored \\\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n",
      "Ignored -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = []\n",
    "\n",
    "for file in glob.glob(\"/home/thibault/dev/these-corpus/data/*.xml\"):\n",
    "    positive.append(file_to_string(file, \"positive\"))\n",
    "\n",
    "negative = []\n",
    "\n",
    "for file in glob.glob(\"./dataset/negative-examples/*.xml\"):\n",
    "    negative.append(file_to_string(file, \"negative\"))\n",
    "\n",
    "\n",
    "def write_dataset(dataset: List[str], filepath: str, cats: Tuple[str, ...] = CATS, delimiter=\"\\t\"):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(f\"[header]\\ttoken\\tlemma\\tpos\\t{delimiter.join(cats)}\\n\")\n",
    "        f.write(\"\\n\\n\\n\".join(dataset))\n",
    "    return True\n",
    "    \n",
    "os.makedirs(\"./dataset/raw/\", exist_ok=True)\n",
    "\n",
    "write_dataset(positive, \"dataset/raw/positive.txt\")\n",
    "write_dataset(negative, \"dataset/raw/negative.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3168b0",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "\n",
    "### Random train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3869a7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "random.shuffle(positive)\n",
    "random.shuffle(negative)\n",
    "\n",
    "train_ratio, dev_ratio = 0.8, 0.1\n",
    "\n",
    "def cut(dataset: float, r_train: float, r_dev: float):\n",
    "    length = len(dataset)\n",
    "    r_train = math.ceil(length*r_train)\n",
    "    r_dev = r_train + math.ceil(length*r_dev)\n",
    "    return dataset[:r_train], dataset[r_train:r_dev], dataset[r_dev:]\n",
    "\n",
    "\n",
    "cut_positive = cut(positive, r_train=train_ratio, r_dev=dev_ratio)\n",
    "cut_negative = cut(negative, r_train=train_ratio, r_dev=dev_ratio)\n",
    "\n",
    "train, dev, test = [pos+neg for pos, neg in zip(cut_positive, cut_negative)]\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(dev)\n",
    "random.shuffle(test)\n",
    "\n",
    "os.makedirs(\"./dataset/split/\", exist_ok=True)\n",
    "write_dataset(train, \"./dataset/split/train.txt\")\n",
    "write_dataset(dev, \"./dataset/split/dev.txt\")\n",
    "write_dataset(test, \"./dataset/split/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefc206",
   "metadata": {},
   "source": [
    "### Metaphore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ecc645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 459\n",
      "False: 2057\n"
     ]
    }
   ],
   "source": [
    "positives_meta = {\n",
    "    True: [],\n",
    "    False: []\n",
    "}\n",
    "for elem in positive:\n",
    "    positives_meta[\"#metaphor\" in elem].append(elem)\n",
    "    \n",
    "for key in positives_meta:\n",
    "    print(f\"{key}: {len(positives_meta[key])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64392860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 / 10 ?\n",
    "m_train, m_dev = split_dataset(positives_meta[True], ratio=.9)\n",
    "m_test = positives_meta[False]\n",
    "\n",
    "# Add a little of generic test\n",
    "neg_train_dev, neg_test = split_dataset(negative, ratio=.7)\n",
    "neg_train, neg_dev = split_dataset(neg_train_dev, ratio=0.9)\n",
    "\n",
    "\n",
    "write_dataset(m_train+neg_train, \"./dataset/metaphors/train.txt\")\n",
    "write_dataset(m_dev+neg_dev, \"./dataset/metaphors/dev.txt\")\n",
    "write_dataset(m_test+neg_test, \"./dataset/metaphors/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1afde",
   "metadata": {},
   "source": [
    "### Inversed metaphore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fc0fec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 / 10 ?\n",
    "m_train, m_dev = split_dataset(positives_meta[False], ratio=.7)\n",
    "m_test = positives_meta[True]\n",
    "\n",
    "# Add a little of generic test\n",
    "neg_train_dev, neg_test = split_dataset(negative, ratio=.7)\n",
    "neg_train, neg_dev = split_dataset(neg_train_dev, ratio=0.9)\n",
    "\n",
    "\n",
    "write_dataset(m_train+neg_train, \"./dataset/inversed-metaphors/train.txt\")\n",
    "write_dataset(m_dev+neg_dev, \"./dataset/inversed-metaphors/dev.txt\")\n",
    "write_dataset(m_test+neg_test, \"./dataset/inversed-metaphors/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cc529",
   "metadata": {},
   "source": [
    "### Terms dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fefffecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 998\n",
      "False: 1518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives_meta = {\n",
    "    True: [],\n",
    "    False: []\n",
    "}\n",
    "for elem in positive:\n",
    "    positives_meta[True in [term in elem for term in (\"futuo\", \"mentul\", \"pedico\", \"cunnus\", \"culus\")]].append(elem)\n",
    "    \n",
    "for key in positives_meta:\n",
    "    print(f\"{key}: {len(positives_meta[key])}\")\n",
    "    \n",
    "\n",
    "# 90 / 10 ?\n",
    "m_train, m_dev = split_dataset(positives_meta[False], ratio=.7)\n",
    "m_test = positives_meta[True]\n",
    "\n",
    "# Add a little of generic test\n",
    "neg_train_dev, neg_test = split_dataset(negative, ratio=.7)\n",
    "neg_train, neg_dev = split_dataset(neg_train_dev, ratio=0.9)\n",
    "\n",
    "\n",
    "write_dataset(m_train+neg_train, \"./dataset/terms/train.txt\")\n",
    "write_dataset(m_dev+neg_dev, \"./dataset/terms/dev.txt\")\n",
    "write_dataset(m_test+neg_test, \"./dataset/terms/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ecb12",
   "metadata": {},
   "source": [
    "### Stats about the partial corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e3ea575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/main-partial/siamese2.txt\n",
      "\tPositives: 0\n",
      "\tNegatives: 1\n",
      "dataset/main-partial/test.txt\n",
      "\tPositives: 251\n",
      "\tNegatives: 426\n",
      "dataset/main-partial/test-full.txt\n",
      "\tPositives: 1783\n",
      "\tNegatives: 3057\n",
      "dataset/main-partial/siamese.txt\n",
      "\tPositives: 1\n",
      "\tNegatives: 1\n",
      "dataset/main-partial/dev.txt\n",
      "\tPositives: 107\n",
      "\tNegatives: 171\n",
      "dataset/main-partial/train.txt\n",
      "\tPositives: 393\n",
      "\tNegatives: 660\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"dataset/main-partial/*.txt\"):\n",
    "    with open(file) as f:\n",
    "        t = f.read()\n",
    "        print(f\"{file}\\n\\tPositives: {t.count('TAG]positive')}\\n\\tNegatives: {t.count('TAG]negative')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
