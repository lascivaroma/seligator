{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f4dbb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 17:47:24.005985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from seligator.main import train_and_get, Seligator\n",
    "from seligator.common.load_save import load\n",
    "from seligator.prediction.tests import run_tests\n",
    "\n",
    "params = load(\"./seligator/siamese.json\")\n",
    "params[\"reader_kwargs\"][\"batch_size\"] = 16\n",
    "params[\"reader_kwargs\"][\"dev_batch_size\"] = 32\n",
    "#params[\"batches_per_epoch\"] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce6aa60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/token_indexers/token_characters_indexer.py:55: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  warnings.warn(\n",
      "WARNING:root:TSV READER uses following metadata encoding MetadataEncoding.IGNORE \n",
      "WARNING:root:TSV Reader keeps following metadata Century, Textgroup, WrittenType, CitationTypes\n",
      "WARNING:allennlp.data.fields.multilabel_field:Your label namespace was '[msd]'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40c2ae1259847578f40d3e7723d57a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab:   0%|          | 0/21955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Adding OOV to following fields: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseClassifier(\n",
      "  (_loss): ContrastiveLoss(\n",
      "    (distance): LpDistance()\n",
      "    (reducer): MultipleReducers(\n",
      "      (reducers): ModuleDict(\n",
      "        (pos_loss): AvgNonZeroReducer()\n",
      "        (neg_loss): AvgNonZeroReducer()\n",
      "      )\n",
      "      (default_reducer): MeanReducer()\n",
      "    )\n",
      "  )\n",
      "  (left_encoder): MixedEmbeddingEncoder(\n",
      "    (_emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "    (features_embedder): FeatureAndTextEmbedder(\n",
      "      (text_embedder): BasicTextFieldEmbedder(\n",
      "        (token_embedder_token): Embedding()\n",
      "        (token_embedder_lemma): Embedding()\n",
      "        (token_embedder_lemma_char): TokenCharactersEncoder(\n",
      "          (_embedding): TimeDistributed(\n",
      "            (_module): Embedding()\n",
      "          )\n",
      "          (_encoder): TimeDistributed(\n",
      "            (_module): LstmSeq2VecEncoder(\n",
      "              (_module): LSTM(100, 150, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "            )\n",
      "          )\n",
      "          (_dropout): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feature_embedder): Linear(in_features=52, out_features=20, bias=True)\n",
      "    )\n",
      "    (features_encoder): HierarchicalAttentionalEncoder(\n",
      "      (gru): ModifiedPytorchSeq2VecWrapper(\n",
      "        (_module): GRU(720, 25, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "      )\n",
      "      (dense): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (right_encoder): MixedEmbeddingEncoder(\n",
      "    (_emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "    (features_embedder): FeatureAndTextEmbedder(\n",
      "      (text_embedder): BasicTextFieldEmbedder(\n",
      "        (token_embedder_token): Embedding()\n",
      "        (token_embedder_lemma): Embedding()\n",
      "        (token_embedder_lemma_char): TokenCharactersEncoder(\n",
      "          (_embedding): TimeDistributed(\n",
      "            (_module): Embedding()\n",
      "          )\n",
      "          (_encoder): TimeDistributed(\n",
      "            (_module): LstmSeq2VecEncoder(\n",
      "              (_module): LSTM(100, 150, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "            )\n",
      "          )\n",
      "          (_dropout): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feature_embedder): Linear(in_features=52, out_features=20, bias=True)\n",
      "    )\n",
      "    (features_encoder): HierarchicalAttentionalEncoder(\n",
      "      (gru): ModifiedPytorchSeq2VecWrapper(\n",
      "        (_module): GRU(720, 25, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "      )\n",
      "      (dense): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "seligator, reader, train, dev = Seligator.init_from_params(**params)\n",
    "train_kwargs = dict(patience=4, num_epochs=50, lr=5e-4, optimizer=\"AdamW\")\n",
    "print(seligator.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dc4c16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Epochs:   50\n",
      "---> Patience: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604edb757ca24c89ac9ed61e55b4b902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50])\n",
      "tensor([[ 0.0000, -0.4233,  0.2099,  0.4136,  0.0000,  0.3802,  0.0000, -0.0177,\n",
      "         -0.0034,  0.0000,  0.0000, -0.0234,  0.0000,  0.1040,  0.0000,  0.0000,\n",
      "          0.1698,  0.0619,  0.0000,  0.0000,  0.0768, -0.1395,  0.0000,  0.0389,\n",
      "          0.0000,  0.0000,  0.0000, -0.2538, -0.8100, -0.6300,  0.0000, -0.3703,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0371,  0.0000,  0.0000,\n",
      "         -0.3589,  0.0000,  0.0000, -0.1459, -0.4604,  0.0000,  0.0000, -0.2193,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0841, -0.4167,  0.0000,  0.4466,  0.0000,  0.5560,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.2312, -0.0209, -0.2353,  0.2078, -0.0438, -0.2636,\n",
      "          0.5456,  0.0000,  0.5773, -0.0066,  0.1834, -0.1682,  0.0958,  0.0000,\n",
      "          0.0000,  0.0000,  0.6819, -0.1265, -0.5892,  0.0000,  0.3286,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.1904,  0.0000, -0.0462,  0.0000,\n",
      "         -0.5957,  0.1885, -0.1362,  0.0000,  0.0000, -0.3119,  0.0000, -0.1483,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, -0.2981,  0.0000,  0.4477,  0.0000,  0.0000,  0.4429, -0.0391,\n",
      "          0.0076, -0.1308,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2834,\n",
      "          0.6430,  0.0000,  0.0000,  0.0268,  0.0000, -0.2986,  0.0000, -0.0828,\n",
      "          0.0000,  0.0000,  0.7079,  0.0000, -0.6033,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.1344,  0.0000, -0.0824,  0.3592,  0.1466,  0.0000,  0.2481,\n",
      "          0.0000,  0.0000, -0.1701, -0.1151,  0.0000,  0.0000, -0.0533, -0.1127,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.1279, -0.4876,  0.0000,  0.0000, -0.3230,  0.0000,  0.0000,  0.0336,\n",
      "          0.2488,  0.0000,  0.0000, -0.2104,  0.0000,  0.0697, -0.1353, -0.1879,\n",
      "          0.3820,  0.0000,  0.1935,  0.0000,  0.2020,  0.0000,  0.0000,  0.0000,\n",
      "          0.1239, -0.5871,  0.5799, -0.2326,  0.0000, -0.2867,  0.5431, -0.2964,\n",
      "          0.2490,  0.2003,  0.1787, -0.0323,  0.1432,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.1916, -0.4869,  0.0000,  0.0000, -0.3293,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.1900,  0.0000,  0.0000,  0.4112,  0.0000,  0.4265,  0.0000, -0.0552,\n",
      "          0.0123,  0.0000,  0.3983, -0.1239,  0.0000,  0.1041,  0.0000, -0.0643,\n",
      "          0.4850,  0.0000,  0.3698,  0.0000,  0.2460,  0.0000,  0.0630, -0.0821,\n",
      "          0.1457,  0.0000,  0.0000,  0.0000,  0.0000, -0.6396,  0.0000,  0.0000,\n",
      "          0.1336,  0.2355,  0.0000,  0.0000,  0.0000,  0.0000, -0.0766,  0.2365,\n",
      "          0.0000,  0.0000, -0.1335, -0.2640, -0.6389, -0.2025,  0.0336, -0.2323,\n",
      "          0.0000,  0.7164],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.6535,  0.7279,  0.0000,  0.0521,\n",
      "          0.0830, -0.2356,  0.3770,  0.0000, -0.2062,  0.1266,  0.0000, -0.1953,\n",
      "          0.0000, -0.1671,  0.0000,  0.0000,  0.0000, -0.2124,  0.0745, -0.0440,\n",
      "          0.0000, -0.5615,  0.0000, -0.3328, -0.6025,  0.0000,  0.0000, -0.2261,\n",
      "          0.1811,  0.0000,  0.2311,  0.0000,  0.1041,  0.0167, -0.1952,  0.0000,\n",
      "          0.0000,  0.3556,  0.0000, -0.1953,  0.0000, -0.3915,  0.0000, -0.1334,\n",
      "         -0.1436,  0.6875],\n",
      "        [ 0.2791,  0.0000,  0.0000,  0.0000,  0.0000,  0.5769,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, -0.1309,  0.0000,  0.1037,  0.0000,  0.0000,\n",
      "          0.6069, -0.0485,  0.0000,  0.0000,  0.2036,  0.0000,  0.0877,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.1959,  0.2634,  0.0000,  0.0306,  0.0000,  0.1167,  0.0000,  0.3221,\n",
      "         -0.5184,  0.3063, -0.2248, -0.2674, -0.5297,  0.0000,  0.0000, -0.2126,\n",
      "         -0.3270,  0.0000],\n",
      "        [ 0.0000, -0.1926,  0.0000,  0.0000, -0.6499,  0.4101,  0.0000, -0.0418,\n",
      "          0.0410,  0.0000,  0.0000,  0.0000, -0.1339,  0.0000,  0.0000, -0.0957,\n",
      "          0.4700,  0.0195,  0.0000, -0.0479,  0.0000, -0.3277,  0.0481, -0.1181,\n",
      "          0.1193, -0.3200,  0.7022,  0.0000,  0.0000,  0.0000,  0.3375,  0.0000,\n",
      "          0.2117,  0.0000,  0.2305,  0.0000,  0.1670,  0.0000,  0.0000,  0.0000,\n",
      "         -0.4477,  0.0000, -0.1526, -0.2163, -0.3546,  0.0000,  0.0000, -0.1403,\n",
      "         -0.0156,  0.0000],\n",
      "        [ 0.0000, -0.7398,  0.0000,  0.3880, -0.4525,  0.3573,  0.3527,  0.0000,\n",
      "         -0.0796, -0.4058,  0.4782,  0.0937, -0.1814,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0012,  0.2591,  0.0000,  0.0031, -0.0725,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000, -0.4471, -0.3019,  0.0000,  0.0000,\n",
      "          0.1498,  0.0000,  0.4942, -0.0441,  0.3614,  0.0000, -0.0994,  0.0859,\n",
      "         -0.1665,  0.2962,  0.0000, -0.3206,  0.0000, -0.2370,  0.0000,  0.0000,\n",
      "         -0.2208,  0.3349]], device='cuda:0', grad_fn=<IndexBackward>) tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -6.2340e-01,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.5525e-01,  0.0000e+00,  0.0000e+00,  4.7190e-02,  0.0000e+00,\n",
      "         -2.5725e-01,  0.0000e+00,  0.0000e+00,  3.9312e-01, -6.6776e-02,\n",
      "          0.0000e+00, -2.5462e-01,  9.3837e-02,  0.0000e+00,  6.3910e-02,\n",
      "         -4.5223e-01,  5.6118e-01, -2.8400e-01, -3.7325e-01,  0.0000e+00,\n",
      "          0.0000e+00, -2.9718e-01,  6.7612e-02,  0.0000e+00,  0.0000e+00,\n",
      "          1.2448e-01,  0.0000e+00,  2.3768e-01, -5.8925e-02,  4.2001e-01,\n",
      "          0.0000e+00,  2.8042e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.3428e-01,  2.0564e-01,  0.0000e+00, -2.8019e-01,  1.3230e+00],\n",
      "        [ 0.0000e+00, -5.0064e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.6790e-01,  2.2619e-01, -3.2974e-03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.8888e-02, -2.2053e-01,  0.0000e+00, -1.8467e-01,\n",
      "          0.0000e+00,  7.6531e-01, -2.0062e-02,  0.0000e+00, -2.9619e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -7.7318e-01,  0.0000e+00, -3.5869e-01, -5.8050e-01, -5.4986e-01,\n",
      "          6.4743e-01, -2.1409e-01,  7.7563e-02,  5.1251e-02,  0.0000e+00,\n",
      "         -6.6624e-02,  4.7468e-01,  0.0000e+00, -4.5512e-02,  0.0000e+00,\n",
      "          0.0000e+00,  9.8965e-02, -1.4538e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.2546e-01,  5.7694e-01],\n",
      "        [ 0.0000e+00, -1.4282e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.1188e-01,  0.0000e+00, -2.2385e-01,\n",
      "          0.0000e+00,  0.0000e+00, -1.6146e-01,  0.0000e+00, -8.4288e-02,\n",
      "         -2.2144e-01,  0.0000e+00,  0.0000e+00,  2.0771e-01, -7.5901e-03,\n",
      "          2.1914e-01, -1.8401e-01,  6.5112e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.9557e-01,  0.0000e+00,  0.0000e+00,\n",
      "          1.9563e-01, -3.6491e-01,  0.0000e+00,  0.0000e+00,  5.5963e-01,\n",
      "         -7.4221e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9415e-01,\n",
      "          0.0000e+00,  2.4687e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -3.7500e-01,  0.0000e+00, -1.1357e-01, -3.9129e-01,  6.5455e-01],\n",
      "        [ 0.0000e+00, -3.3910e-01,  7.1908e-01,  2.5984e-01,  0.0000e+00,\n",
      "          3.9022e-01,  0.0000e+00,  0.0000e+00,  2.1020e-01,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4282e-02, -7.2852e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9663e-01,  1.0911e-03,\n",
      "          2.0465e-01, -9.9373e-02,  1.6757e-01,  6.0864e-03,  0.0000e+00,\n",
      "         -7.3360e-01,  0.0000e+00, -2.4009e-01, -2.3255e-01,  0.0000e+00,\n",
      "          4.7992e-01, -2.3171e-01,  2.0689e-01,  2.8247e-01,  2.1118e-01,\n",
      "          0.0000e+00,  1.1988e-01,  4.9384e-02, -1.0818e-01,  0.0000e+00,\n",
      "          0.0000e+00,  2.5627e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.2749e-01,  0.0000e+00, -2.8905e-01,  6.8485e-01],\n",
      "        [ 0.0000e+00, -3.9050e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          3.2359e-01,  0.0000e+00,  1.6242e-02,  4.4599e-02, -2.1963e-01,\n",
      "          3.0027e-01,  0.0000e+00, -2.1032e-01,  1.7609e-01,  0.0000e+00,\n",
      "         -1.3319e-01,  2.3091e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.7993e-01,  0.0000e+00, -9.4637e-02, -3.2760e-03,\n",
      "         -6.7673e-01,  6.7543e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.4604e-01,\n",
      "          4.4248e-02,  2.5550e-01,  1.7510e-02, -1.6535e-01,  0.0000e+00,\n",
      "         -6.9478e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6957e-01,\n",
      "          0.0000e+00,  6.1480e-02, -1.4588e-01,  0.0000e+00,  8.6733e-01],\n",
      "        [ 0.0000e+00, -2.4778e-01,  4.3198e-01,  4.1769e-01,  0.0000e+00,\n",
      "          0.0000e+00,  2.6965e-01, -3.2939e-02, -2.1083e-02,  0.0000e+00,\n",
      "          4.3752e-01, -2.2652e-01,  0.0000e+00,  0.0000e+00,  4.6184e-02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -9.5704e-04,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.9787e-01,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.9550e-01,\n",
      "         -9.5053e-02,  2.4431e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -4.5913e-01,  3.2863e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  3.6395e-01, -5.5360e-01,\n",
      "          4.4399e-01,  1.8647e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          2.7502e-01, -1.8894e-01, -3.1484e-01,  0.0000e+00, -1.4884e-01,\n",
      "         -1.8266e-01,  0.0000e+00, -2.4291e-02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  1.9303e-01,  0.0000e+00,  0.0000e+00,\n",
      "         -7.5085e-01,  7.8215e-01,  0.0000e+00,  0.0000e+00, -4.6287e-01,\n",
      "          0.0000e+00, -3.9594e-01,  0.0000e+00,  1.2672e-01,  3.6462e-01,\n",
      "         -1.2277e-02,  2.8096e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.8556e-01,  0.0000e+00, -5.1162e-01,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3510e-01,  0.0000e+00]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels must be a 1D tensor of shape (batch_size,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33830/2686068566.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseligator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrain_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m data, img = run_tests(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"dataset/main/test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset_reader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"siamese.best.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/seligator/main.py\u001b[0m in \u001b[0;36mtrain_and_get\u001b[0;34m(model, train, dev, lr, use_cpu, **train_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     train_model(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/seligator/training/trainer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, dev_loader, cuda_device, patience, num_epochs, lr, optimizer, optimizer_params)\u001b[0m\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36m_try_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs_completed\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_after_epochs_completed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_amp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                     \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                     \u001b[0mbatch_group_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/training/gradient_descent_trainer.py\u001b[0m in \u001b[0;36mbatch_outputs\u001b[0;34m(self, batch, for_training)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m \u001b[0madding\u001b[0m \u001b[0many\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mregularization\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/seligator/models/siamese.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0msim_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/pytorch_metric_learning/losses/base_metric_loss_function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, labels, indices_tuple)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mc_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/pytorch_metric_learning/utils/common_functions.py\u001b[0m in \u001b[0;36mcheck_shapes\u001b[0;34m(embeddings, labels)\u001b[0m\n\u001b[1;32m    420\u001b[0m         )\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels must be a 1D tensor of shape (batch_size,)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels must be a 1D tensor of shape (batch_size,)"
     ]
    }
   ],
   "source": [
    "model = train_and_get(seligator.model, train, dev, **train_kwargs)\n",
    "data, img = run_tests(\n",
    "    \"dataset/main/test.txt\",\n",
    "    dataset_reader=reader, model=model, dump=f\"siamese.best.csv\"\n",
    ")\n",
    "seligator.save_model(\"siamese_saved_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
