{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123c67cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-13 09:18:35.438157: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from seligator.common.params import MetadataEncoding, Seq2VecEncoderType, BasisVectorConfiguration\n",
    "from seligator.main import train_and_get, Seligator\n",
    "from seligator.common.load_save import load\n",
    "from seligator.prediction.tests import run_tests\n",
    "\n",
    "from seligator.models.siamese import SiameseClassifier\n",
    "from seligator.models.classifier import FeatureEmbeddingClassifier\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "def get_json_fn(fn):\n",
    "    return f\"dumped-results/{fn}.json\"\n",
    "\n",
    "def already_done(fn):\n",
    "    return os.path.exists(get_json_fn(fn))\n",
    "\n",
    "def save_json(fn, obj):\n",
    "    with open(get_json_fn(fn), \"w\") as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "\n",
    "# Run tests on Vectors Categories\n",
    "def get_kwargs():\n",
    "    METADATA_CATS = (\"Century\", \"Textgroup\", \"WrittenType\", \"CitationTypes\")\n",
    "    BVC = BasisVectorConfiguration(\n",
    "        categories=METADATA_CATS\n",
    "    )\n",
    "    return dict(\n",
    "        token_features=(\"lemma_char\", \"lemma\"),\n",
    "        msd_features=(\"case\", \"numb\", \"gend\", \"mood\", \"tense\", \"voice\", \"person\", \"deg\"),\n",
    "        seq2vec_encoder_type=Seq2VecEncoderType.LSTM,\n",
    "        basis_vector_configuration=BVC,\n",
    "        agglomerate_msd=False,\n",
    "        reader_kwargs={\n",
    "            \"batch_size\": 4, \n",
    "            \"metadata_encoding\": MetadataEncoding.IGNORE,\n",
    "            \"metadata_tokens_categories\": METADATA_CATS\n",
    "        },\n",
    "        model_embedding_kwargs=dict(\n",
    "            keep_all_vocab=True,\n",
    "            pretrained_embeddings={\n",
    "                # \"token\": \"~/Downloads/latin.embeddings\",\n",
    "            #    \"token\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.token.word2vec.kv\",\n",
    "            #    \"lemma\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.lemma.word2vec.kv.header\"\n",
    "            },\n",
    "            trainable_embeddings={\"token\": False, \"lemma\": False},\n",
    "            emb_dims={\"token\": 200, \"lemma\": 200}\n",
    "        ),\n",
    "        encoder_hidden_size=64,\n",
    "        batches_per_epoch=None,\n",
    "        model_class=FeatureEmbeddingClassifier,\n",
    "        use_bert_highway=False,\n",
    "        bert_dir = \"./bert/latin_bert\"\n",
    "    )\n",
    "\n",
    "    \n",
    "def get_train_and_get_kwargs():\n",
    "    return dict(patience=4, num_epochs=20, lr=5e-4, optimizer=\"AdamW\")\n",
    "\n",
    "def jqs(data):\n",
    "    return \"-\".join(sorted(list(data)))\n",
    "\n",
    "def get_filename(params, prefix = \"model\"):\n",
    "    remaped = []\n",
    "    for key in sorted(list(params.keys())):\n",
    "        if isinstance(params[key], str) and not params[key]:\n",
    "            continue\n",
    "        if isinstance(params[key], str) and \"-\" in params[key]:\n",
    "            remaped.append(f\"{key}-\"+\"\".join([\n",
    "                \"\".join([\n",
    "                    subv[:3].lower().capitalize()\n",
    "                    for subv in v.split(\"_\")\n",
    "                ])\n",
    "                for v in params[key].split(\"-\")\n",
    "            ]))\n",
    "        else:\n",
    "            remaped.append(f\"{key}-{params[key]}\")\n",
    "    print(remaped)\n",
    "    return prefix+\"--\"+\"__\".join(remaped)\n",
    "\n",
    "def merge(source, destination):\n",
    "    \"\"\" Source = New , Destination = Default\n",
    "    run me with nosetests --with-doctest file.py\n",
    "\n",
    "    >>> a = { 'first' : { 'all_rows' : { 'pass' : 'dog', 'number' : '1' } } }\n",
    "    >>> b = { 'first' : { 'all_rows' : { 'fail' : 'cat', 'number' : '5' } } }\n",
    "    >>> merge(b, a) == { 'first' : { 'all_rows' : { 'pass' : 'dog', 'fail' : 'cat', 'number' : '5' } } }\n",
    "    True\n",
    "    \"\"\"\n",
    "    for key, value in source.items():\n",
    "        if isinstance(value, dict):\n",
    "            # get node or create one\n",
    "            node = destination.setdefault(key, {})\n",
    "            merge(value, node)\n",
    "        else:\n",
    "            destination[key] = value\n",
    "\n",
    "    return destination\n",
    "\n",
    "def run_and_save(model_name, prepare_model_kwargs, train_kwargs, model_name_prefix: str = \"model\"):\n",
    "    fn = f\"{model_name_prefix}-{model_name}\"\n",
    "    \n",
    "    if already_done(fn):\n",
    "        print(f\"Already trained {fn}\")\n",
    "        return {}\n",
    "    \n",
    "    seligator, reader, train, dev = Seligator.init_from_params(\n",
    "        **prepare_model_kwargs\n",
    "    )\n",
    "    _ = train_and_get(seligator.model, train, dev, **train_kwargs)\n",
    "    seligator.save_model(f\"./models/{fn}\")\n",
    "    data, img = run_tests(\n",
    "        f\"{prepare_model_kwargs.get('folder', 'dataset/main')}/test.txt\",\n",
    "        dataset_reader=reader, model=seligator.model, dump=f\"./models/{fn}/test.csv\"\n",
    "    )\n",
    "    out = {\n",
    "        fn: {\n",
    "            **{x:v for x, v in data.items() if isinstance(v, float)},\n",
    "            **train_kwargs\n",
    "        }\n",
    "    }\n",
    "    save_json(fn, out)\n",
    "    return out\n",
    "\n",
    "def get_siamese():\n",
    "    siamese = get_kwargs()\n",
    "    siamese[\"model_class\"] = SiameseClassifier\n",
    "    siamese[\"batches_per_epoch\"] = 20\n",
    "    siamese_train_kwargs = get_train_and_get_kwargs()\n",
    "    siamese_train_kwargs[\"num_epochs\"] = siamese_train_kwargs[\"num_epochs\"] * int(1351 // siamese[\"batches_per_epoch\"])\n",
    "    siamese_train_kwargs[\"patience\"] = 10\n",
    "    return siamese, siamese_train_kwargs\n",
    "\n",
    "def get_classic():\n",
    "    return get_kwargs(), get_train_and_get_kwargs()\n",
    "\n",
    "RUNS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c2e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what can be JSONIFIED\n",
    "\n",
    "import json\n",
    "\n",
    "# https://stackoverflow.com/questions/24481852/serialising-an-enum-member-to-json\n",
    "\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    _PUBLIC_ENUMS = {\n",
    "        \"MetadataEncoding\": MetadataEncoding, \n",
    "        \"Seq2VecEncoderType\": Seq2VecEncoderType, \n",
    "        #\"BasisVectorConfiguration\": BasisVectorConfiguration\n",
    "    }\n",
    "    _PUBLIC_CLASSES = {\n",
    "        \"SiameseClassifier\": SiameseClassifier,\n",
    "        \"FeatureEmbeddingClassifier\": FeatureEmbeddingClassifier\n",
    "    }\n",
    "\n",
    "    def default(self, obj):\n",
    "        if type(obj) in CustomEncoder._PUBLIC_ENUMS.values():\n",
    "            return {\"__enum__\": str(obj)}\n",
    "        elif isinstance(obj, type):\n",
    "            if obj in CustomEncoder._PUBLIC_CLASSES.values():\n",
    "                return {\"__type__\": str(obj.__name__)}\n",
    "            else:\n",
    "                print(obj)\n",
    "        elif isinstance(obj, BasisVectorConfiguration):\n",
    "            return {\"__basis_vector_configuration__\": obj.to_dict()}\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "    @staticmethod\n",
    "    def object_hook(d):\n",
    "        if \"__enum__\" in d:\n",
    "            name, member = d[\"__enum__\"].split(\".\")\n",
    "            return getattr(CustomEncoder._PUBLIC_ENUMS[name], member)\n",
    "        elif \"__type__\" in d:\n",
    "            return CustomEncoder._PUBLIC_CLASSES[d[\"__type__\"]]\n",
    "        elif \"__basis_vector_configuration__\" in d:\n",
    "            return BasisVectorConfiguration.from_dict(d[\"__basis_vector_configuration__\"])\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "\n",
    "PRE_LEMMA = {\n",
    "    \"model_embedding_kwargs\":{\n",
    "        \"pretrained_embeddings\": {\n",
    "            \"lemma\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.lemma.word2vec.kv.header\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6788d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_runs(get_kw, has_linear=False, prefix=\"model-\", folder=None):\n",
    "    if has_linear:\n",
    "        name = lambda string: \"Linear\"+string\n",
    "    else:\n",
    "        name = lambda string: \"Siamese\"+string\n",
    "        \n",
    "    NoAuthor_METADATA_CATS = (\"Century\", \"WrittenType\", \"CitationTypes\")\n",
    "    NoAuthor_BVC = BasisVectorConfiguration(\n",
    "        categories=NoAuthor_METADATA_CATS\n",
    "    )\n",
    "    NoAuthorCitation_METADATA_CATS = (\"Century\", \"WrittenType\")\n",
    "    NoAuthorCitation_BVC = BasisVectorConfiguration(\n",
    "        categories=NoAuthorCitation_METADATA_CATS\n",
    "    )\n",
    "    \n",
    "    PRE_LEMMA = {\n",
    "        \"model_embedding_kwargs\":{\n",
    "            \"pretrained_embeddings\": {\n",
    "                \"lemma\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.lemma.word2vec.kv.header\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Changes = [\n",
    "        # Use raw Bert\n",
    "        (name(\"BertTokenOnly\"), {\"token_features\": (\"token_subword\", )}, {}),\n",
    "        # Use raw Bert No Highway\n",
    "        (name(\"BertTokenOnlyWithHighway\"), {\"token_features\": (\"token_subword\", ), \"use_bert_highway\": True}, {}),\n",
    "        # Use raw Bert + Lemma\n",
    "        (name(\"BertLemma-HAN\"), {\n",
    "            \"token_features\": (\"token_subword\", \"lemma\", \"lemma_char\"),\n",
    "            \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "            \"use_bert_highway\": False\n",
    "        }, {}),\n",
    "        (name(\"Vanilla\"), {}, {}),\n",
    "        # Raw Features + MSD + Vanilla LSTM\n",
    "        (name(\"VanillaAggloMSD\"), {\"agglomerate_msd\": True}, {}),\n",
    "        # Raw Features + MSD + HAN\n",
    "        (name(\"VanillaAggloMSD-HAN\"), {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN}, {}),\n",
    "        # Raw Features + MSD + Enriched LSTM\n",
    "        (name(\"VanillaAggloMSD-EnriLSTM\"),\n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL}}, {}),\n",
    "        # Raw Features + MSD + Enriched Attention\n",
    "        (name(\"VanillaAggloMSD-EnriAttention\"),\n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataAttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL}}, {}),\n",
    "        # Raw Features + MSD + Attention\n",
    "        (name(\"VanillaAggloMSD-AttentPool\"),\n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.AttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL}}, {}),\n",
    "        # Now we use Metadata Tokens !\n",
    "        # Raw Features + MSD + Attention\n",
    "        #({ # Does not work because AttentionPooling expects metadata_vector\n",
    "        #    \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_TOKEN},\n",
    "        #    \"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.AttentionPooling}, {}),\n",
    "        # Raw Features + MSD + Attention\n",
    "        (name(\"VanillaAggloMSD-Metatoks-HAN\"),\n",
    "         {\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_TOKEN},\n",
    "            \"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN}, {}),\n",
    "        #\n",
    "        #\n",
    "        # With Pretrained\n",
    "        #\n",
    "        #\n",
    "        # Raw Features + MSD + Vanilla LSTM\n",
    "        (name(\"VanillaAggloMSD-Pretrained\"), {\"agglomerate_msd\": True, **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + HAN\n",
    "        (name(\"VanillaAggloMSD-HAN-Pretrained\"), {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "          **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + Enriched LSTM\n",
    "        (name(\"VanillaAggloMSD-EnriLSTM-Pretrained\"), \n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "          **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + Enriched Attention\n",
    "        (name(\"VanillaAggloMSD-EnriAttention-Pretrained\"), \n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataAttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "          **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + Attention\n",
    "        (name(\"VanillaAggloMSD-AttentPool-Pretrained\"), \n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.AttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "          **PRE_LEMMA}, {}),\n",
    "    ]\n",
    "    if has_linear:\n",
    "        Changes = Changes + [\n",
    "            (\n",
    "                name(\"Vanilla-LinearEnriched\"), \n",
    "                 {\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True}\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"Vanilla-LinearEnriched-Pretrained\"), \n",
    "                {\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-HAN-LinearEnriched-Pretrained\"), \n",
    "                {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-EnriLSTM-LinearEnriched-Pretrained\"), \n",
    "                {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            # Apparently, its the best, so let's play with input features\n",
    "            # (\"lemma_char\", \"lemma\", \"case\", \"numb\", \"gend\", \"mood\", \"tense\", \"voice\", \"person\", \"deg\")\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained\"), \n",
    "                {\"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                 \"msd_features\": [],\n",
    "              \"agglomerate_msd\": False, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}\n",
    "            ),\n",
    "            # No Author in metadata\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthor\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"msd_features\": [],\n",
    "                    \"agglomerate_msd\": True,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthor_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthor_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthor\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"msd_features\": [],\n",
    "                    \"agglomerate_msd\": False,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthor_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthor_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-HAN-LinearEnriched-Pretrained-NoAuthor\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"agglomerate_msd\": True,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthor_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthor_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-EnriLSTM-Pretrained-NoAuthor\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"agglomerate_msd\": True,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthor_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthor_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": False},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-EnriLSTM-Pretrained-NoAuthor\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"msd_features\": [],\n",
    "                    \"agglomerate_msd\": False,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthor_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthor_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": False},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            # No Author No Citation in metadata\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthorCitation\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"msd_features\": [],\n",
    "                    \"agglomerate_msd\": True,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthorCitation_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthorCitation_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthorCitation\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"msd_features\": [],\n",
    "                    \"agglomerate_msd\": False,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthorCitation_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthorCitation_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-HAN-LinearEnriched-Pretrained-NoAuthorCitation\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"agglomerate_msd\": True,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthorCitation_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthorCitation_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-EnriLSTM-Pretrained-NoAuthorCitation\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"agglomerate_msd\": True,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthorCitation_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthorCitation_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": False},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-EnriLSTM-Pretrained-NoAuthorCitation\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"msd_features\": [],\n",
    "                    \"agglomerate_msd\": False,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthorCitation_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthorCitation_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": False},\n",
    "                **PRE_LEMMA\n",
    "            }, {})\n",
    "        ]\n",
    "    for idx, (model_name, model_kw, train_kw) in enumerate(Changes):\n",
    "        defaults_model, default_trains = get_kw()\n",
    "        model_kw = merge(model_kw, defaults_model)\n",
    "        train_kw = merge(train_kw, default_trains)\n",
    "        if folder:\n",
    "            model_kw[\"folder\"] = folder\n",
    "        run_and_save(model_name, model_kw, train_kw, model_name_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fe1ce",
   "metadata": {},
   "source": [
    "# Siamese Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42cf700f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already trained model--LinearBertTokenOnly\n",
      "Already trained model--LinearBertTokenOnlyWithHighway\n",
      "Already trained model--LinearBertLemma-HAN\n",
      "Already trained model--LinearVanilla\n",
      "Already trained model--LinearVanillaAggloMSD\n",
      "Already trained model--LinearVanillaAggloMSD-HAN\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM\n",
      "Already trained model--LinearVanillaAggloMSD-EnriAttention\n",
      "Already trained model--LinearVanillaAggloMSD-AttentPool\n",
      "Already trained model--LinearVanillaAggloMSD-Metatoks-HAN\n",
      "Already trained model--LinearVanillaAggloMSD-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-HAN-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-EnriAttention-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-AttentPool-Pretrained\n",
      "Already trained model--LinearVanilla-LinearEnriched\n",
      "Already trained model--LinearVanilla-LinearEnriched-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM-LinearEnriched-Pretrained\n",
      "Already trained model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained\n",
      "Already trained model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthor\n",
      "Already trained model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthor\n",
      "Already trained model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained-NoAuthor\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM-Pretrained-NoAuthor\n",
      "Already trained model--LinearVanilla-NoMorph-EnriLSTM-Pretrained-NoAuthor\n",
      "Already trained model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthorCitation\n",
      "Already trained model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthorCitation\n",
      "Already trained model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained-NoAuthorCitation\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM-Pretrained-NoAuthorCitation\n",
      "Already trained model--LinearVanilla-NoMorph-EnriLSTM-Pretrained-NoAuthorCitation\n"
     ]
    }
   ],
   "source": [
    "do_runs(get_classic, has_linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc281171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "RUNS = []\n",
    "for file in glob.glob(\"dumped-results/*.json\"):\n",
    "    with open(file) as f:\n",
    "        RUNS.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4069cfee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model--LinearBertTokenOnlyWithHighway 0.8759231905465288\n",
      "model--LinearVanillaAggloMSD-EnriAttention 0.8788774002954209\n",
      "model--model_name 0.880354505169867\n",
      "model--LinearVanillaAggloMSD-Pretrained 0.8833087149187593\n",
      "model--LinearBertTokenOnly 0.8906942392909897\n",
      "model--LinearVanillaAggloMSD-AttentPool 0.8906942392909897\n",
      "model--LinearBertLemma-HAN 0.8921713441654358\n",
      "model--LinearVanilla 0.8936484490398818\n",
      "model--LinearVanillaAggloMSD-HAN 0.8951255539143279\n",
      "model--LinearVanillaAggloMSD 0.896602658788774\n",
      "model--LinearVanillaAggloMSD-HAN-Pretrained 0.8980797636632201\n",
      "model--LinearVanillaAggloMSD-EnriAttention-Pretrained 0.8995568685376661\n",
      "model--LinearVanillaAggloMSD-Metatoks-HAN 0.9025110782865583\n",
      "model--LinearVanilla-LinearEnriched 0.9039881831610044\n",
      "model--LinearVanillaAggloMSD-EnriLSTM-Pretrained-NoAuthorCitation 0.9069423929098966\n",
      "model--LinearVanilla-NoMorph-EnriLSTM-Pretrained-NoAuthorCitation 0.9098966026587888\n",
      "model--LinearVanilla-NoMorph-EnriLSTM-Pretrained-NoAuthor 0.9098966026587888\n",
      "model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthorCitation 0.9113737075332349\n",
      "model--LinearVanillaAggloMSD-AttentPool-Pretrained 0.9113737075332349\n",
      "model--LinearVanillaAggloMSD-EnriLSTM-Pretrained-NoAuthor 0.9113737075332349\n",
      "model--LinearVanillaAggloMSD-EnriLSTM-Pretrained 0.9172821270310192\n",
      "model--LinearVanillaAggloMSD-EnriLSTM-LinearEnriched-Pretrained 0.9217134416543574\n",
      "model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained-NoAuthorCitation 0.9217134416543574\n",
      "model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthor 0.9261447562776958\n",
      "model--LinearVanillaAggloMSD-EnriLSTM 0.9261447562776958\n",
      "model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained 0.9350073855243722\n",
      "model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained-NoAuthor 0.9394387001477105\n",
      "model--LinearVanilla-NoMorph-HAN-LinearEnriched-Pretrained 0.9438700147710487\n",
      "model--LinearVanilla-LinearEnriched-Pretrained 0.9453471196454948\n"
     ]
    }
   ],
   "source": [
    "best, best_key = 0, None\n",
    "sorts = sorted([(list(run.keys())[0], list(run.values())[0][\"accuracy\"]) for run in RUNS], key=lambda x: x[1])\n",
    "for key in sorts:\n",
    "    print(key[0], key[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
