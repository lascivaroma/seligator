{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123c67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seligator.common.params import MetadataEncoding, Seq2VecEncoderType, BasisVectorConfiguration\n",
    "from seligator.main import train_and_get, Seligator\n",
    "from seligator.common.load_save import load\n",
    "from seligator.prediction.tests import run_tests\n",
    "\n",
    "from seligator.models.siamese import SiameseClassifier\n",
    "from seligator.models.classifier import FeatureEmbeddingClassifier\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "def get_json_fn(fn):\n",
    "    return f\"dumped-results/{fn}.json\"\n",
    "\n",
    "def already_done(fn):\n",
    "    return os.path.exists(get_json_fn(fn))\n",
    "\n",
    "def save_json(fn, obj):\n",
    "    with open(get_json_fn(fn), \"w\") as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "\n",
    "# Run tests on Vectors Categories\n",
    "def get_kwargs():\n",
    "    METADATA_CATS = (\"Century\", \"Textgroup\", \"WrittenType\", \"CitationTypes\")\n",
    "    BVC = BasisVectorConfiguration(\n",
    "        categories=METADATA_CATS\n",
    "    )\n",
    "    return dict(\n",
    "        token_features=(\"lemma_char\", \"lemma\"),\n",
    "        msd_features=(\"case\", \"numb\", \"gend\", \"mood\", \"tense\", \"voice\", \"person\", \"deg\"),\n",
    "        seq2vec_encoder_type=Seq2VecEncoderType.LSTM,\n",
    "        basis_vector_configuration=BVC,\n",
    "        agglomerate_msd=False,\n",
    "        reader_kwargs={\n",
    "            \"batch_size\": 4, \n",
    "            \"metadata_encoding\": MetadataEncoding.IGNORE,\n",
    "            \"metadata_tokens_categories\": METADATA_CATS\n",
    "        },\n",
    "        model_embedding_kwargs=dict(\n",
    "            keep_all_vocab=True,\n",
    "            pretrained_embeddings={\n",
    "                # \"token\": \"~/Downloads/latin.embeddings\",\n",
    "            #    \"token\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.token.word2vec.kv\",\n",
    "            #    \"lemma\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.lemma.word2vec.kv.header\"\n",
    "            },\n",
    "            trainable_embeddings={\"token\": False, \"lemma\": False},\n",
    "            emb_dims={\"token\": 200, \"lemma\": 200}\n",
    "        ),\n",
    "        encoder_hidden_size=64,\n",
    "        batches_per_epoch=None,\n",
    "        model_class=FeatureEmbeddingClassifier,\n",
    "        use_bert_highway=False,\n",
    "        bert_dir = \"./bert/latin_bert\"\n",
    "    )\n",
    "\n",
    "    \n",
    "def get_train_and_get_kwargs():\n",
    "    return dict(patience=4, num_epochs=20, lr=5e-4, optimizer=\"AdamW\")\n",
    "\n",
    "def jqs(data):\n",
    "    return \"-\".join(sorted(list(data)))\n",
    "\n",
    "def get_filename(params, prefix = \"model\"):\n",
    "    remaped = []\n",
    "    for key in sorted(list(params.keys())):\n",
    "        if isinstance(params[key], str) and not params[key]:\n",
    "            continue\n",
    "        if isinstance(params[key], str) and \"-\" in params[key]:\n",
    "            remaped.append(f\"{key}-\"+\"\".join([\n",
    "                \"\".join([\n",
    "                    subv[:3].lower().capitalize()\n",
    "                    for subv in v.split(\"_\")\n",
    "                ])\n",
    "                for v in params[key].split(\"-\")\n",
    "            ]))\n",
    "        else:\n",
    "            remaped.append(f\"{key}-{params[key]}\")\n",
    "    print(remaped)\n",
    "    return prefix+\"--\"+\"__\".join(remaped)\n",
    "\n",
    "def merge(source, destination):\n",
    "    \"\"\" Source = New , Destination = Default\n",
    "    run me with nosetests --with-doctest file.py\n",
    "\n",
    "    >>> a = { 'first' : { 'all_rows' : { 'pass' : 'dog', 'number' : '1' } } }\n",
    "    >>> b = { 'first' : { 'all_rows' : { 'fail' : 'cat', 'number' : '5' } } }\n",
    "    >>> merge(b, a) == { 'first' : { 'all_rows' : { 'pass' : 'dog', 'fail' : 'cat', 'number' : '5' } } }\n",
    "    True\n",
    "    \"\"\"\n",
    "    for key, value in source.items():\n",
    "        if isinstance(value, dict):\n",
    "            # get node or create one\n",
    "            node = destination.setdefault(key, {})\n",
    "            merge(value, node)\n",
    "        else:\n",
    "            destination[key] = value\n",
    "\n",
    "    return destination\n",
    "\n",
    "def run_and_save(model_name, prepare_model_kwargs, train_kwargs, model_name_prefix: str = \"model\"):\n",
    "    fn = f\"{model_name_prefix}-{model_name}\"\n",
    "    \n",
    "    if already_done(fn):\n",
    "        print(f\"Already trained {fn}\")\n",
    "        return {}\n",
    "    \n",
    "    seligator, reader, train, dev = Seligator.init_from_params(\n",
    "        **prepare_model_kwargs\n",
    "    )\n",
    "    _ = train_and_get(seligator.model, train, dev, **train_kwargs)\n",
    "    seligator.save_model(f\"./models/{fn}\")\n",
    "    data, img = run_tests(\n",
    "        \"dataset/main/test.txt\",\n",
    "        dataset_reader=reader, model=seligator.model, dump=f\"./models/{fn}/test.csv\"\n",
    "    )\n",
    "    out = {\n",
    "        fn: {\n",
    "            **{x:v for x, v in data.items() if isinstance(v, float)},\n",
    "            **train_kwargs\n",
    "        }\n",
    "    }\n",
    "    save_json(fn, out)\n",
    "    return out\n",
    "\n",
    "def get_siamese():\n",
    "    siamese = get_kwargs()\n",
    "    siamese[\"model_class\"] = SiameseClassifier\n",
    "    siamese[\"batches_per_epoch\"] = 20\n",
    "    siamese_train_kwargs = get_train_and_get_kwargs()\n",
    "    siamese_train_kwargs[\"num_epochs\"] = siamese_train_kwargs[\"num_epochs\"] * int(1351 // siamese[\"batches_per_epoch\"])\n",
    "    siamese_train_kwargs[\"patience\"] = 10\n",
    "    return siamese, siamese_train_kwargs\n",
    "\n",
    "def get_classic():\n",
    "    return get_kwargs(), get_train_and_get_kwargs()\n",
    "\n",
    "RUNS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c2e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what can be JSONIFIED\n",
    "\n",
    "import json\n",
    "\n",
    "# https://stackoverflow.com/questions/24481852/serialising-an-enum-member-to-json\n",
    "\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    _PUBLIC_ENUMS = {\n",
    "        \"MetadataEncoding\": MetadataEncoding, \n",
    "        \"Seq2VecEncoderType\": Seq2VecEncoderType, \n",
    "        #\"BasisVectorConfiguration\": BasisVectorConfiguration\n",
    "    }\n",
    "    _PUBLIC_CLASSES = {\n",
    "        \"SiameseClassifier\": SiameseClassifier,\n",
    "        \"FeatureEmbeddingClassifier\": FeatureEmbeddingClassifier\n",
    "    }\n",
    "\n",
    "    def default(self, obj):\n",
    "        if type(obj) in CustomEncoder._PUBLIC_ENUMS.values():\n",
    "            return {\"__enum__\": str(obj)}\n",
    "        elif isinstance(obj, type):\n",
    "            if obj in CustomEncoder._PUBLIC_CLASSES.values():\n",
    "                return {\"__type__\": str(obj.__name__)}\n",
    "            else:\n",
    "                print(obj)\n",
    "        elif isinstance(obj, BasisVectorConfiguration):\n",
    "            return {\"__basis_vector_configuration__\": obj.to_dict()}\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "    @staticmethod\n",
    "    def object_hook(d):\n",
    "        if \"__enum__\" in d:\n",
    "            name, member = d[\"__enum__\"].split(\".\")\n",
    "            return getattr(CustomEncoder._PUBLIC_ENUMS[name], member)\n",
    "        elif \"__type__\" in d:\n",
    "            return CustomEncoder._PUBLIC_CLASSES[d[\"__type__\"]]\n",
    "        elif \"__basis_vector_configuration__\" in d:\n",
    "            return BasisVectorConfiguration.from_dict(d[\"__basis_vector_configuration__\"])\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "\n",
    "PRE_LEMMA = {\n",
    "    \"model_embedding_kwargs\":{\n",
    "        \"pretrained_embeddings\": {\n",
    "            \"lemma\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.lemma.word2vec.kv.header\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6788d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_runs(get_kw, has_linear=False):\n",
    "    if has_linear:\n",
    "        name = lambda string: \"Linear\"+string\n",
    "    else:\n",
    "        name = lambda string: \"Siamese\"+string\n",
    "        \n",
    "    NoAuthor_METADATA_CATS = (\"Century\", \"WrittenType\", \"CitationTypes\")\n",
    "    NoAuthor_BVC = BasisVectorConfiguration(\n",
    "        categories=NoAuthor_METADATA_CATS\n",
    "    )\n",
    "    \n",
    "    PRE_LEMMA = {\n",
    "        \"model_embedding_kwargs\":{\n",
    "            \"pretrained_embeddings\": {\n",
    "                \"lemma\": \"~/dev/these/notebooks/4 - Detection/data/embs_models/model.lemma.word2vec.kv.header\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Changes = [\n",
    "        # Use raw Bert\n",
    "        (name(\"BertTokenOnly\"), {\"token_features\": (\"token_subword\", )}, {}),\n",
    "        # Use raw Bert No Highway\n",
    "        (name(\"BertTokenOnlyWithHighway\"), {\"token_features\": (\"token_subword\", ), \"use_bert_highway\": True}, {}),\n",
    "        # Use raw Bert + Lemma\n",
    "        (name(\"BertLemma-HAN\"), {\n",
    "            \"token_features\": (\"token_subword\", \"lemma\", \"lemma_char\"),\n",
    "            \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "            \"use_bert_highway\": False\n",
    "        }, {}),\n",
    "        (name(\"Vanilla\"), {}, {}),\n",
    "        # Raw Features + MSD + Vanilla LSTM\n",
    "        (name(\"VanillaAggloMSD\"), {\"agglomerate_msd\": True}, {}),\n",
    "        # Raw Features + MSD + HAN\n",
    "        (name(\"VanillaAggloMSD-HAN\"), {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN}, {}),\n",
    "        # Raw Features + MSD + Enriched LSTM\n",
    "        (name(\"VanillaAggloMSD-EnriLSTM\"),\n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL}}, {}),\n",
    "        # Raw Features + MSD + Enriched Attention\n",
    "        (name(\"VanillaAggloMSD-EnriAttention\"),\n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataAttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL}}, {}),\n",
    "        # Raw Features + MSD + Attention\n",
    "        (name(\"VanillaAggloMSD-AttentPool\"),\n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.AttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL}}, {}),\n",
    "        # Now we use Metadata Tokens !\n",
    "        # Raw Features + MSD + Attention\n",
    "        #({ # Does not work because AttentionPooling expects metadata_vector\n",
    "        #    \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_TOKEN},\n",
    "        #    \"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.AttentionPooling}, {}),\n",
    "        # Raw Features + MSD + Attention\n",
    "        (name(\"VanillaAggloMSD-Metatoks-HAN\"),\n",
    "         {\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_TOKEN},\n",
    "            \"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN}, {}),\n",
    "        #\n",
    "        #\n",
    "        # With Pretrained\n",
    "        #\n",
    "        #\n",
    "        # Raw Features + MSD + Vanilla LSTM\n",
    "        (name(\"VanillaAggloMSD-Pretrained\"), {\"agglomerate_msd\": True, **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + HAN\n",
    "        (name(\"VanillaAggloMSD-HAN-Pretrained\"), {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "          **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + Enriched LSTM\n",
    "        (name(\"VanillaAggloMSD-EnriLSTM-Pretrained\"), \n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "          **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + Enriched Attention\n",
    "        (name(\"VanillaAggloMSD-EnriAttention-Pretrained\"), \n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataAttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "          **PRE_LEMMA}, {}),\n",
    "        # Raw Features + MSD + Attention\n",
    "        (name(\"VanillaAggloMSD-AttentPool-Pretrained\"), \n",
    "         {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.AttentionPooling,\n",
    "            \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "          **PRE_LEMMA}, {}),\n",
    "    ]\n",
    "    if has_linear:\n",
    "        Changes = Changes + [\n",
    "            (\n",
    "                name(\"Vanilla-LinearEnriched\"), \n",
    "                 {\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True}\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"Vanilla-LinearEnriched-Pretrained\"), \n",
    "                {\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-HAN-LinearEnriched-Pretrained\"), \n",
    "                {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            (\n",
    "                name(\"VanillaAggloMSD-EnriLSTM-LinearEnriched-Pretrained\"), \n",
    "                {\"agglomerate_msd\": True, \"seq2vec_encoder_type\": Seq2VecEncoderType.MetadataLSTM,\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "            # Apparently, its the best, so let's play with input features\n",
    "            # (\"lemma_char\", \"lemma\", \"case\", \"numb\", \"gend\", \"mood\", \"tense\", \"voice\", \"person\", \"deg\")\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained\"), \n",
    "                {\"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "              \"agglomerate_msd\": False, \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                \"reader_kwargs\": {\"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL},\n",
    "                \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}\n",
    "            ),\n",
    "            # No Author in metadata\n",
    "            (\n",
    "                name(\"Vanilla-NoMorph-HAN-LinearEnriched-Pretrained-NoAuthor\"), \n",
    "                {\n",
    "                    \"token_features\": (\"lemma_char\", \"lemma\"), #No morph\n",
    "                    \"agglomerate_msd\": False,\n",
    "                    \"seq2vec_encoder_type\": Seq2VecEncoderType.HAN,\n",
    "                    \"reader_kwargs\": {\n",
    "                        \"metadata_encoding\": MetadataEncoding.AS_CATEGORICAL,\n",
    "                        \"metadata_tokens_categories\": NoAuthor_METADATA_CATS\n",
    "                    },\n",
    "                    \"basis_vector_configuration\": NoAuthor_BVC,\n",
    "                    \"additional_model_kwargs\": { \"metadata_linear\": True},\n",
    "                **PRE_LEMMA\n",
    "            }, {}),\n",
    "        ]\n",
    "    for idx, (model_name, model_kw, train_kw) in enumerate(Changes):\n",
    "        defaults_model, default_trains = get_kw()\n",
    "        model_kw = merge(model_kw, defaults_model)\n",
    "        train_kw = merge(train_kw, default_trains)\n",
    "        RUNS.update(run_and_save(model_name, model_kw, train_kw, model_name_prefix=f\"model-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fe1ce",
   "metadata": {},
   "source": [
    "# Siamese Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42cf700f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already trained model--LinearBertTokenOnly\n",
      "Already trained model--LinearBertTokenOnlyWithHighway\n",
      "Already trained model--LinearBertLemma-HAN\n",
      "Already trained model--LinearVanilla\n",
      "Already trained model--LinearVanillaAggloMSD\n",
      "Already trained model--LinearVanillaAggloMSD-HAN\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM\n",
      "Already trained model--LinearVanillaAggloMSD-EnriAttention\n",
      "Already trained model--LinearVanillaAggloMSD-AttentPool\n",
      "Already trained model--LinearVanillaAggloMSD-Metatoks-HAN\n",
      "Already trained model--LinearVanillaAggloMSD-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-HAN-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-EnriAttention-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-AttentPool-Pretrained\n",
      "Already trained model--LinearVanilla-LinearEnriched\n",
      "Already trained model--LinearVanilla-LinearEnriched-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-HAN-LinearEnriched-Pretrained\n",
      "Already trained model--LinearVanillaAggloMSD-EnriLSTM-LinearEnriched-Pretrained\n",
      "False ('lemma_char', 'lemma')\n",
      "GetMeBert(use_bert=False, embedder=None, indexer=None, tokenizer=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/token_indexers/token_characters_indexer.py:55: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14da8a766ab4e0190b73b4d0ffebd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab:   0%|          | 0/5427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:allennlp.modules.token_embedders.embedding:The embeddings file has an unknown file extension \".header\". We will assume the file is an (uncompressed) text file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bef00521a74adda0556367c44978dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Epochs:   20\n",
      "---> Patience: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfa86a75e5e46ebb8564b1dcb28cf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/est-lascivuum-non-est/seligator/models/classifier.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(logits)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44c968b0e014c49a8875d6c6c65d4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6072e37eee4ef084cc28475ea08490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbde94cf25a4db6b54541483cfc03da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe9fe65f62f44e39f544a50a96cf49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18177ef1bfda42288c95b21344ea9156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e388609a304a01874d65ade01f6933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab51222c8bb4bf8baf0a8bf37fb5d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8be4393eb3e41d1ae5770fa6f085046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a302d41decc41859e6c7d86f8d9827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bbf3e48c0744bc87fe3b95d33a5089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7996751a648d465ebe25548cadaa36b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab40dfb4d074c4fb0b02cd5215bbac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd583c8b5d0491b96cb5eee1e37252a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678fd4f8f0c24d47a36497ff3437f199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa67729cae54570adc4bd68e6121f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceacd0d63854658b7f0f3be41e8fe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a89a403f5e46a0920a434ecd3e9f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5021606e2b44e6e89d724cb25fb33f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd5abed129946ca8a89dc05e79ed0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2e98b8d90349a895828dcd19df9afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thibault/dev/est-lascivuum-non-est/seligator/prediction/tests.py:57: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  disp.figure_.show()\n",
      "/home/thibault/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/token_indexers/token_characters_indexer.py:55: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False ('lemma_char', 'lemma')\n",
      "GetMeBert(use_bert=False, embedder=None, indexer=None, tokenizer=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01e8238acd8482aa55f6e97c5e5a8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab:   0%|          | 0/5427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:allennlp.data.vocabulary:Namespace: Textgroup_ns_labels\n",
      "ERROR:allennlp.data.vocabulary:Token: urn:cts:latinLit:phi1236\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"'urn:cts:latinLit:phi1236' not found in vocab namespace 'Textgroup_ns_labels', and namespace does not contain the default OOV token ('@@UNKNOWN@@')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/vocabulary.py\u001b[0m in \u001b[0;36mget_token_index\u001b[0;34m(self, token, namespace)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'urn:cts:latinLit:phi1236'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/vocabulary.py\u001b[0m in \u001b[0;36mget_token_index\u001b[0;34m(self, token, namespace)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_oov_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '@@UNKNOWN@@'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61329/3679396871.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_classic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_linear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_61329/4289136510.py\u001b[0m in \u001b[0;36mdo_runs\u001b[0;34m(get_kw, has_linear)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mmodel_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mtrain_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_trains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mRUNS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"model-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_61329/3551567418.py\u001b[0m in \u001b[0;36mrun_and_save\u001b[0;34m(model_name, prepare_model_kwargs, train_kwargs, model_name_prefix)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     seligator, reader, train, dev = Seligator.init_from_params(\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mprepare_model_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     )\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/seligator/main.py\u001b[0m in \u001b[0;36minit_from_params\u001b[0;34m(token_features, msd_features, bert_dir, seq2vec_encoder_type, model_class, additional_model_kwargs, batches_per_epoch, reader_kwargs, encoder_hidden_size, agglomerate_msd, use_bert_highway, model_embedding_kwargs, basis_vector_configuration, training, vocabulary_path, folder)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             train, dev, vocab, reader = generate_all_data(\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0mtoken_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mmsd_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsd_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/seligator/training/trainer.py\u001b[0m in \u001b[0;36mgenerate_all_data\u001b[0;34m(token_features, msd_features, ratio_train, batch_size, batches_per_epoch, get_me_bert, instance_type, folder, **tsv_reader_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    155\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mdev_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/data_loaders/simple_data_loader.py\u001b[0m in \u001b[0;36mindex_with\u001b[0;34m(self, vocab)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/instance.py\u001b[0m in \u001b[0;36mindex_fields\u001b[0;34m(self, vocab)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/fields/label_field.py\u001b[0m in \u001b[0;36mindex\u001b[0;34m(self, vocab)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip_indexing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             self._label_id = vocab.get_token_index(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_namespace\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             )\n",
      "\u001b[0;32m~/dev/est-lascivuum-non-est/env/lib/python3.8/site-packages/allennlp/data/vocabulary.py\u001b[0m in \u001b[0;36mget_token_index\u001b[0;34m(self, token, namespace)\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Namespace: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m    739\u001b[0m                     \u001b[0;34mf\"'{token}' not found in vocab namespace '{namespace}', and namespace \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34mf\"does not contain the default OOV token ('{self._oov_token}')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"'urn:cts:latinLit:phi1236' not found in vocab namespace 'Textgroup_ns_labels', and namespace does not contain the default OOV token ('@@UNKNOWN@@')\""
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_runs(get_classic, has_linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc281171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "RUNS = []\n",
    "for file in glob.glob(\"dumped-results/*.json\"):\n",
    "    with open(file) as f:\n",
    "        RUNS.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069cfee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best, best_key = 0, None\n",
    "sorts = sorted([(list(run.keys())[0], list(run.values())[0][\"accuracy\"]) for run in RUNS], key=lambda x: x[1])\n",
    "for key in sorts:\n",
    "    print(key[0], key[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
